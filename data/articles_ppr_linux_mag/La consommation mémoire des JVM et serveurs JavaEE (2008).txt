La consommation mémoire des JVM et serveurs JavaEE
  

Pour les lecteurs ayant une connaissance superficielle des technologies Java, ou pour les développeurs Java confirmés, cette article traite de la gestion mémoire des JVMs, des serveurs J2EE et des approches permettant d'améliorer les applications en production. Nous allons expliquer comment fonctionne la JVM, quelles sont les différentes techniques de caches utilisées dans les applications J2EE, comment déterminer la taille mémoire minimum d'un applicatif, et par là, calculer la taille maximum à allouer pour obtenir le maximum de performance.
Par Philippe PRADOS - 2008
www.prados.fr
L'expérience montre que de nombreux développeurs Java n'ont aucune connaissance des mécanismes mis en place dans les serveurs J2EE pour améliorer les performances et ignorent comment la JVM fonctionne. Cela entraîne un paramétrage et un développement contre-productif, un gâchis de ressources et un impact écologique trop important car les serveurs ne sont pas mutualisés.
La jvm
Commençons par expliquer ce qu'est une machine virtuelle, et comment elle fonctionne vis-à-vis de la mémoire. Une JVM est une simulation d'un microprocesseur. Les instructions en pseudo langage machine sont interprétées par un programme : la machine virtuelle. Elle effectue des manipulations mémoires, invoque des fonctions des systèmes d'exploitation, alloue et libère la mémoire, etc. Cette approche permet d'écrire et de compiler un programme une seule fois, et de l'exécuter dans tous les environnements, d'une carte à puce à un Cray One en cluster.
Pour optimiser l'interprétation des instructions de la machine virtuelle, les dernières générations vont transformer à la volées les instructions en langage machine natif. Cette compilation tardive ne peut utiliser toutes les techniques avancées des compilateurs traditionnels, car le temps de compilation ne doit pas pénaliser l'application. Les dernières générations de machines virtuelles savent identifier les 10% de code les plus sollicités pour utiliser des techniques d'optimisations plus agressives. Le temps nécessaire à cette compilation est compensé par le fait que le code résultant est le plus sollicité.
Un programme classique alloue de la mémoire au fur et à mesure qu'il en a besoin. Il en demande au système d'exploitation qui se charge de lui réserver des zones de tailles suffisantes. En théorie, sans limitation des ressources par le système d'exploitation, un programme peut consommer toute la mémoire disponible sur la machine. Lors de la libération d'une zone mémoire, il y a des trous dans la mémoire. À la longue, la mémoire est parsemée de trous, comme un gruyère. Une allocation peut ne pas aboutir, alors que mis bout à bout, la mémoire encore libre est suffisante. De nombreuses techniques à base d’adressage virtuel, cherchent à optimiser cela, pour regrouper les trous et optimiser l'occupation mémoire, mais au sein d'un programme compilé, il persiste de nombreux trous de gruyère.
  

Une machine virtuelle Java fonctionne différemment. Elle se charge de libérer automatiquement les zones mémoires n'étant plus nécessaires, et de regrouper les zones utilisées pour réunir les trous d'un coté et le gruyère de l'autre.
  

Le mécanisme de nettoyage se met en fonctionnement lorsque toute la mémoire réservée à la JVM est consommée. Du point de vue du système d'exploitation, une machine virtuelle est un programme comme un autre. La mémoire nécessaire est allouée au fur et à mesure. Les zones dites libres par la JVM ne le sont pas du point de vue du système d'exploitation.
  

Pour compenser ces deux stratégies, il est nécessaire d'indiquer la taille maximum qu'une machine virtuelle peut consommer. Cette taille sera la limite à partir de laquelle la machine virtuelle doit faire le ménage dans sa propre mémoire. Sans cette taille limite, la machine virtuelle continuerait à demander de la mémoire, tant qu'il y en a de disponible dans le système d'exploitation. Elle pourrait même saturer la mémoire virtuelle du système d'exploitation, entraînant des allers et retours disque importants. Du point de vue du système d'exploitation, la mémoire réservée à la machine virtuelle est considérée comme utilisée, alors qu'elle peut être complètement vide, vue de la JVM.
Comment fonctionne le nettoyage de la mémoire, appelé également « ramasse miette » ou « garbage collector » ? Lorsqu'une allocation ne peut aboutir, la JVM va partir d'un premier pointeur, et parcourir tous les chemins possibles. Un drapeau est déposé sur chaque objet traversé. Ensuite, il suffit de reprendre la liste de tous les objets en mémoire et de supprimer les objets n'ayant pas de drapeau.
  

Ce mécanisme ne peut s'exécuter lorsque le programme fonctionne. En effet, des objets pourraient être créés ou perdus entre l'étape de traversée des objets et l'étape de nettoyage. Il est donc nécessaire d'interrompre tous traitements de la JVM le temps que s'effectue le ménage. Les applications Java sont alors figées.
On remarque de cet algorithme, qu'il ne faut surtout pas que la JVM utilise la mémoire virtuelle du système d'exploitation. En effet, sinon, pour parcourir tous les objets, le système doit passer son temps à décharger la mémoire de segment, et à en charger d'autres pour ne traverser qu'un seul pointeur. Il doit recommencer tout cela lors de la deuxième étape. C'est une vraie catastrophe en terme de performance. En aucun cas, la taille mémoire maximum de la JVM doit être supérieure à la mémoire physique disponible après le chargement du système d'exploitation.
Pour réduire au maximum les interruptions de la JVM dues à l'exécution du ramasse miettes, elle utilise différentes stratégies. Il a été constaté que les objets ont une durée de vie soit très courte, soit très longue. Les objets sont créés juste le temps de faire un traitement d'une méthode, ou au contraire, ils servent à mémoriser un état important, pour une période plus longue, un cache par exemple.
Fort de ce constat, la mémoire de la JVM est découpée en plusieurs parties. Une zone est réservée aux objets à durées de vie courtes. Une autre zone est réservée aux objets à durées de vie longues. Très régulièrement, un algorithme de nettoyage des objets à durée de vie courte est exécuté. Cet algorithme est très rapide, mais est incapable d'identifier tous les objets à nettoyer. Par exemple, il a du mal à identifier des groupes d'objets se référençant les uns les autres, mais dont il n'existe aucun chemin pour l'atteindre. On appelle ces situations des îlot. Pour tous les autres objets, l'algorithme identifie très rapidement les objets obsolètes. Si un objet survis à cet algorithme, un compteur de durée de vie est incrémenté. Si un seuil est dépassé, l'objet est déplacé dans la zone mémoire des objets à durée de vie longue. Il sera traité lorsqu'une allocation mémoire est impossible (Full GC). Soit il résiste et reste en mémoire, soit il n'est plus accessible et est supprimé de la mémoire.
De cette description, nous comprenons qu'il y un fort impact à adapter la taille réservées à la zone mémoire pour les objets à courte durée de vie et la zone mémoire maximum réservée à la JVM. Cela à deux effets contradictoires. Avec beaucoup de mémoire, le nettoyage complet (Full GC) arrive plus rarement, mais il dure plus longtemps. Avec moins de mémoire, le nettoyage complet arrive plus souvent, mais dure moins longtemps.
  

Quel est l'objectif à atteindre ? Adapter la taille mémoire pour obtenir un temps moyen de quelques secondes pour le nettoyage complet. Contrairement à une idée reçue, ce n'est pas en augmentant la mémoire réservée à la JVM qu'on améliore les performances. Si le nettoyage complet prend trop de temps, cela interrompt tous les traitements de tous les utilisateurs, au risque de déclencher des timeouts.
Les différents caches
Nous allons survoler les différents caches mis en place dans un serveur J2EE. Cela nous permettra de comprendre comment calculer et optimiser les paramètres des JVMs.
Un serveur J2EE est conçu pour traiter des milliers d'utilisateurs simultanément. Bien entendu, cela est une vue de l'esprit. Il n'y a pas mille threads s'exécutant en même temps. Comment est-ce alors possible ?
Taille de la queue TCP des ouvertures de connexions
Dans un premier temps, il y a une limite sur le nombre de demandes d'ouverture de connexion en attente. Au delà de cette limite, un paquet réseau est retourné à l'utilisateur par la pile TCP/IP de l'OS, pour lui signaler qu'il n'est pas possible d'obtenir une connexion, que le serveur est surchargé.
Cette taille est paramétrable dans les serveurs d'applications. Par exemple, le paramètre acceptCount d'un <Connector/> de Tomcat permet d'indiquer une limite. Il est préférable de maintenir les connexions en dehors du serveur si celui-ci n'est pas capable de les satisfaire. L'impact d'une augmentation de ce paramètre est négligeable en terme de ressource par rapport aux approches que nous allons survoler. Comme sur la route, il est préférable que chacun roule au pas qu'avoir des bouchons car certains désirent aller plus vite que les autres. L'excès est l'ennemi du bien.
Nombre de threads
Ensuite, il y a une limite du nombre de thread pouvant être exécuté en même temps (Paramètre maxThreads de Tomcat). Cette limite doit être judicieusement choisie pour gérer la charge, sans pénaliser les performances. En effet, en multipliant le nombre de threads, on multiplie les changements de contextes par le système d'exploitation et la consommation mémoire.
L'idéal est de n'avoir jamais aucun changement de contexte. Ainsi, la CPU est utilisées à 100%, et uniquement pour des traitements efficace. (Certains systèmes d'exploitations utilisent cette approche, comme Windows version 1.0, ce n'est pas tout jeune. Les traitements doivent être coopératifs pour partager la CPU.)
Mais sérialiser tous les traitements n'est pas non plus une bonne idée. En effet, les traitements passent une grande partie de leurs temps à attendre des ressources, la lecture ou l'écriture d'un fichier, un paquet réseau, l'exécution d'une requête SQL, etc. En parallélisant les traitements, il est possible d'exploiter la CPU pendant ces temps morts. Il faut trouver un juste équilibre entre le nombre de threads et l'impact négatif du changement de contexte lors du passage d'un thread à un autre. L'expérience montre qu'il est préférable de laisser les connexions en dehors du serveur, le temps de terminer les threads en cours.
De nouvelles techniques avancées permettent d'exploiter les API du JDK 5, permettant une gestion asynchrone des ressources. Ainsi, un seul thread peut traiter plusieurs requêtes. Lors de la lecture d'un fichier par exemple, une demande est effectuée au système d'exploitation, mais la main n'est pas perdue par le thread. Il peut continuer à travailler, et s'occuper par exemple d'un autre utilisateur. Lorsque les premiers octets du fichier sont disponibles, un événement est envoyé au programme qui peut alors reprendre le traitement du premier utilisateur dès que cela est possible. Ces techniques avancées sont complexes et non prises en compte par les développeurs J2EE (pour le moment ;-).
Que deviennent les requêtes supplémentaires, ne pouvant être traitées par les threads en cours ? Elles sont mises en attente. Comme indiqué ci-dessus, une liste de requêtes est géré par la pile TCP/IP. Tant qu'il n'existe aucun thread disponible, l'ouverture de connexion est suspendue. Dès qu'un thread est disponible, il accepte la connexion et obtient le flux de la requête. Il doit s'en charger le plus rapidement possible. Si le traitement est trop long, car il attend de nombreuses ressources ou des ressources lentes, il y a consommation excessive d'un thread, au détriment des requêtes en attente. Au pire, tous les threads peuvent être en attente de ressources, la CPU ne fait plus rien, pourtant, il existe d'autres requêtes en attente de traitement qui ne sont pas encore sorties de la pile IP.
Il est important de traiter chaque requête le plus vite possible ou d'augmenter le nombre de threads pour compenser une programmation peu optimisée.
Connexion à la base de données
Une fois qu'un traitement est démarré, il demande généralement à communiquer avec une base de données. En théorie, il faudrait, pour chaque requête, ouvrir une connexion à la base de données, s'identifier avec le nom de l'utilisateur, et enfin, envoyer la requête SQL avant d'attendre la réponse.
Ces étapes prennent du temps. Pour éviter de les effectuer à chaque requête, les serveurs J2EE utilisent un « pool » de connexions. Ce pool est transparent pour le développeur. Lors qu'un traitement demande l'ouverture d'une connexion à la base de donnée, la demande est capturée par le serveur J2EE. Il regarde dans le pool de connexion s'il n'en existe pas déjà ayant strictement les mêmes paramètres de connexion. Si c'est le cas, il recycle la connexion et la retourne au processus. Si ce n'est pas le cas, il ouvre une nouvelle connexion et l'ajoute au pool.
Lorsque le processus n'a plus besoin de la connexion, il la ferme. Cette fermeture est également capturée par le serveur J2EE qui se charge de replacer la connexion dans le pool de connexion, sans la fermer.
On comprend de ce processus qu'il n'est pas pertinent d'ouvrir des connexions avec des noms d'utilisateurs différents. En effet, si chaque connexion porte le nom de l'utilisateur, chacune est différente et il n'est plus possible d'utiliser le pool de connexions. En effet, lors de la recherche d'une connexion identique, il répond dans ce cas, systématiquement par la négative.
Les applications J2EE utilisent généralement des utilisateurs de bases de données banalisés. Il n'est alors plus possible de tracer les requêtes d'un utilisateur particulier, sur la base de donnée.
En général, chaque requête cherche à communiquer avec la base de données. Il est donc pertinent d'indiquer une taille de pool de connexion équivalent au nombre de threads accepté par le serveur J2EE. Il ne sert à rien d'utiliser une valeur supérieure, car il n'est pas possible d'avoir plus de traitements que le maximum acceptés par le serveur J2EE.
Faut-il indiquer une valeur inférieure ? Supposons que soixante pour-cent des requêtes HTTP nécessitent un accès à la base de données. Faut-il indiquer une taille pour le pool de connexion à soixante pour-cent du nombre de threads ? À priori, cela semble une bonne idée.
Mais, cela suppose que la charge est toujours égale à soixante pour-cent. Il ne s'agit pas d'une charge uniforme, mais d'une moyenne. Il y a une chance sur deux que la connexion soit sous les soixante pour-cent, et une chance sur deux qu'elle soit au dessus des soixante pour-cents.
Donc, il y de grandes chances que toutes les requêtes traitées en même temps par tous les threads aient besoin d'un accès à la base de données. Avec seulement une partie des requêtes satisfaites, il reste quarante pour-cent des requêtes bloquées, car il n'y a pas de connexion à la base de données de disponible. Donc, quarante pour-cent des threads qui ne servent à rien. Au contraire, si exceptionnellement, toutes les requêtes traitées simultanément n'ont pas besoin de la base de données, il y a quand même soixante pour-cent de connexions à la base restées ouvertes.
En conclusion, il ne faut pas confondre charge ponctuelle et moyenne. En utilisant un pool de connexion strictement identique au nombre de thread simultanés, la situation est toujours optimum. Si la base accepte d'ouvrir autant de connexions, pourquoi s'en priver ?
Que faire si la base de données ne peut supporter le nombre de connexions voulu ? Il faut réduire le nombre de threads et augmenter la taille de la file d'attente TCP/IP. En effet, à quoi sert de traiter une requête, si c'est pour être immédiatement suspendu car le processus n'arrive pas à communiquer avec la base de données ? L'ajout de threads inutiles entraîne une surconsommation de la mémoire (jusqu'à 1024K pour la pile de chaque thread) et un fort travail pour le scheduler du système d'exploitation. Tous cela pour être bloqué dès le début du traitement. L'impact mémoire est au contraire négligeable si le paquet réseau est gardé dans la pile TCP/IP, le temps de libérer un thread.
Parfois, dans de rares cas, l'application utilise plusieurs utilisateurs banalisés de la base de données. Cela permet de bénéficier de privilèges différents. Par exemple, pour des raisons de sécurité, un utilisateur de la base de données n'est autorisé qu’à la consultation. Un autre peut également apporter des modifications aux données. L'applicatif peut utiliser l'un ou l'autre utilisateur suivant les besoins. Ainsi, en cas de vulnérabilité dans l'applicatif, les risques sont réduits. Une vulnérabilité dans une requête de consultation ne permet pas au pirate d'apporter des modifications à la base de données. Dans ce cas, la taille du pool de connexions à la base de donnée doit être égale au nombre d'utilisateurs multiplié par le nombre de threads simultanés. En effet, par manque de chance, tous les traitements peuvent être simultanément en lecture ou en écriture.
Requêtes préparées
Une fois la connexion établie ou obtenue implicitement par le pool J2EE, l'applicatif cherche à exécuter des requêtes à la base de données. JDBC propose deux approches : exécuter directement la requête ou préparer l'exécution de la requête d'une part, et l'exécuter d'autre part. En effet, pour traiter une requête, la base de données doit, dans un premier temps analyser la syntaxe et préparer un plan d'exécution. Ensuite, la base de données peut exécuter le plan pour retourner ou apporter des modifications aux données. L'étape de préparation du plan est coûteuse en terme de performance, et peut être réutilisé entre différentes requêtes basées sur le même modèle.
La demande de données avec une clause WHERE nom='moi' utilise strictement le même plan d'exécution que pour la clause WHERE nom='toi'. Seule la valeur 'moi' ou 'toi' change. Elle peut être portée par une variable de requête SQL. Il est alors possible de préparer les requêtes en ajoutant quelques variables (WHERE nom='?'). Lors de l'exécution proprement dite, le programme doit valoriser les variables et demander l'exécution du plan.
Les serveurs J2EE savent maintenir un cache des requêtes préparées (prepared statement en anglais). Comme chaque plan est dépendant de l'utilisateur connecté, (privilèges ou visibilités des données différentes suivant les utilisateurs), le cache est associé à chaque connexion. Certains drivers ou implémentations du cache savent partager le cache des requêtes préparées entre plusieurs connexions, mais ce n'est pas le comportement standard. Cela dépend des capacités des bases de données.
Il faut avoir à l'esprit que la taille du cache des requêtes préparées doit être multiplié par la taille du cache des connexions à la base de données pour connaître l'impact mémoire.
Si le développeur n'utilise que des requêtes préparées, il est possible d'initialiser, dès le lancement du programme, toutes les requêtes possibles pour l'application, de préparer tous les plans d'exécution possibles. Cela entraîne qu'il n'y a jamais de requêtes calculées par le programme. Pour cela, il ne doit exister aucun code s'occupant de construire dynamiquement une clause WHERE, ORDER BY ou autre.
Si les développeurs respectent bien les bonnes pratiques, en analysant le code, il est possible de calculer le nombre précis de requêtes différentes que peut exécuter le programme. La taille du cache de requêtes préparées doit correspondre à ce calcul. Ainsi, toutes les requêtes seront optimisées. Si ce n'est pas le cas, les requêtes les plus anciennes seront sacrifiées au bénéfice des requêtes les plus récentes. Ce n'est pas optimum. Tout le bénéfice attendu par le découpage entre la préparation de la requête et son exécution est perdu.
Moins la taille du cache des requêtes préparées est proche du nombre de requêtes possibles, plus la probabilité de ne pas trouver la requête est grande. Le problème est que le cache est partagé par tous les utilisateurs, et non par un seul. Même si la plupart des utilisateurs font des consultations, une seule mise à jour peut éjecter une requête de consultation pourtant nécessaire à d'autres utilisateurs. En utilisant une taille de cache équivalent au nombre de requête possibles, cela n'arrive plus.
Une autre approche consiste à utiliser deux connexions différentes, avec des utilisateurs différents, pour bénéficier de caches de requêtes préparées différents. La première connexion ne s'occupe que des consultations. Elle peut avoir un cache important. La deuxième connexion s'occupe des mises à jour et peut avoir un cache plus petit, voir inférieur au nombre de requêtes de mise à jour. Il n'y a plus conflit d'intérêts entre les caches.
Si votre programme calcule dynamiquement des requêtes, il est important de le revoir. Il existe toujours une solution pour éviter les calculs.
Par exemple, il n'est pas possible d'utiliser une variable de requête SQL pour les clauses ORDER BY. S'il existe deux ou trois possibilités pour un ORDER BY, utilisez des requêtes préparées pour les différentes versions. Le programme de calcul se charge alors, non pas de calculer la requête, mais de sélectionner une des versions préparées.
Cache métier
Les applications utilisent généralement leurs propres caches, pour mémoriser une fois pour toutes les données de références ou d'autres objets métiers complexes à construire. Soit le programme se charge d'initialiser ses caches lors du démarrage, soit le cache est alimenté au fur et à mesure des besoins de l'application.
Attention, ces caches doivent obligatoirement avoir une taille limitée et maîtrisée. Cette taille correspond au nombre fini d'objets à charger en mémoire pour les données de référence, ou à une taille limite arbitraire. Dans ce cas, il faut utiliser un mécanisme de LRU (Last Recent Used). C'est à dire que les objets dans le cache, n'ayant pas été sollicités depuis longtemps, peuvent être sacrifiés au bénéfice des objets fraîchement chargés en mémoire. Cela limite le nombre d'instances en mémoire. Sans cette limite, la consommation mémoire de votre applicatif n'est pas maîtrisée, et vous vous exposez à de graves déconvenues. Au fur et à mesure que votre applicatif survit en production, la mémoire est consommé jusqu'au jour où... Les pirates savent exploiter ces développements malheureux pour faire tomber les serveurs.
Pour contourner cela, l'approche naïve consiste à augmenter la taille mémoire de la JVM, entraînant par effet de bord, une charge de travail plus importante pour le ramasse miette. Cela bloque alors l'application et tous les utilisateurs pendant plusieurs secondes. Le problème doit être réglé dans le code, et non en modifiant un paramètre de la JVM.
Les sessions
Le protocole HTTP est un protocole sans état. C'est à dire que contrairement aux autres protocoles permettant de télécharger des fichiers (FTP par exemple), il n'y a pas de connexion maintenue ouverte entre le client et le serveur. C'est cette particularité qui permet à ce protocole de servir des milliers d'utilisateurs, sans saturation de la pile IP ou de la mémoire du serveur. Après chaque requête d'un utilisateur, la connexion est coupée.
Pour contourner cette limitation, lors de la première requête d'un utilisateur, un ticket lui est associé. Ce ticket est livré à l'utilisateur généralement sous forme de cookie. Il existe bien d'autres techniques pour faire cela : production de pages spécifiques pour chaque utilisateur avec le ticket dans chaque URL ; utilisation d'un nom de domaine dont le préfixe correspond au ticket de l'utilisateur ; ajout d'un champ caché dans chaque formulaire, etc.
Pour les requêtes suivantes, l'utilisateur doit présenter le ticket afin que le serveur puisse relier les différentes requêtes d'un même utilisateur. Le serveur doit alors maintenir la session de l'utilisateur, avec les différentes informations que ce dernier a saisies au fur et à mesure de sa navigation sur le site.
Comme il n'existe pas de connexion entre l'utilisateur et le serveur, ce dernier ne peut pas savoir si l'utilisateur va cliquer encore sur un lien ou s'il est parti vers d'autres occupations. Il est impossible de savoir quand la session doit être détruite. Pour contourner la difficulté, les serveurs d'applications considèrent qu'une session qui n'a pas été utilisée depuis trente minutes ne sera plus utilisée. Elle peut être détruire de la mémoire.
Nous avons donc en mémoire, une collection d'objets mémorisant les sessions de tous les utilisateurs. Pouvant potentiellement avoir des milliers d'utilisateurs en mêmes temps, même s'ils ne demandent pas tous simultanément de nouvelles pages, il y a un risque de saturer la mémoire du serveur. Pour éviter cela, seul un nombre limité de sessions est gardé en mémoire. Au delà, les sessions sont déposées sur disque, dans un fichier, une base de données ou n'importe quel support permettant de décharger la mémoire. Lorsqu'un utilisateur se présente avec son ticket, le serveur regarde dans un premier temps dans les sessions encore en mémoire. S'il trouve le ticket, il peut exploiter la session de l'utilisateur. S'il ne le trouve pas, il commence par identifier la session en mémoire ayant été sollicitée il y a le plus longtemps. Cette session est déposée sur disque pour libérer une place en mémoire. Puis, la session de l'utilisateur est recherchée sur le disque et chargée en mémoire. Les sessions en mémoire servent de cache aux sessions sur disque. C'est une sorte de mécanisme de mémoire virtuelle dont on connaît les impacts négatifs au niveau des performances.
Nous voyons que tout est fait dans l'architecture des serveurs J2EE pour réduire la consommation mémoire. À chaque excès, il faut déposer une session sur le disque et en charger une autre. Cela prend du temps. Un accès disque est plusieurs milliers de fois plus lent qu'un accès mémoire. D'autant plus si la session est volumineuse. Voilà pourquoi il est conseillé de ne pas avoir de session ayant une taille mémoire supérieur à quinze kilo-octets.
Comment calculer la taille mémoire d'une session ? C'est pratiquement impossible. En effet, chaque JVM ajoute plus ou moins d'octets à chaque allocation mémoire. La seule chose qu'il est possible de faire est d'obtenir une estimation de la taille de la session. L'approche la plus simple consiste à sérialiser la session dans un pseudo flux, ayant pour charge de calculer le nombre d'octets produits. Le code proposé ci-dessous a l'avantage, par rapport à d'autres approches, de ne consommer que peu d'octets en mémoire. En effet, ce n'est pas le moment de gâcher de la mémoire :-)
class SizeOutputStream extends OutputStream
{
  private long length_;
  @Override
  public void write(int arg0) throws IOException
  {
    ++length_;
  }
  @Override
  public void write(byte[] buf) throws IOException
  {
    length_+=buf.length;
  }
  @Override
  public void write(byte[] buf,int pos,int s)
  {
    length_+=s;
  }
  @Override
  public long getLength()
  {
    return length_;
  }
};


SizeOutputStream s=new SizeOutputStream();
new ObjectOutputStream(s).writeObject(getSession());
System.out.println("Estimation de la taille de la session="+s.getLength());
Un indicateur peut alors mémoriser la taille maximum qu'a prise la session au cours de son utilisation. L'indicateur est généralement placé en ... session. Dès qu'il augmente, une trace est effectuée. Ou bien, la trace est écrite lors de la destruction de la session après le timeout. Un singleton peut également servir à identifier la taille maximum prise par une session quelconque, indépendamment de l'utilisateur. Cela permet d'identifier les excès des programmeurs.
Ces estimations permettent de savoir si la session augmente de plus en plus, si elle dépasse les 15 Ko car un fichier PDF de cinq cents page a été produit et mémorisé dans la session (ne riez pas, cela se voit tous les jours).
Souvent, les développeurs indiquent qu'ils ne peuvent connaître la taille de la session, car elle mémorise le résultat d'une requête dont on ne connaît pas le nombre d'éléments. C'est une grave erreur et une bombe à retardement pour l'exploitation. Que ce passe t’il si tous les utilisateurs présent en mémoires récupèrent le maximum d'éléments ? La JVM plante. Que ce passe t’il lorsqu'une nouvelle session arrive ? Il faut sauver une session énorme sur disque. Cela bloque tout le serveur d'applications car, tant que la sauvegarde n'est pas terminée, il n'y a plus de thread disponible. Il ne faut pas procéder ainsi. On ne garde pas le résultat d'une requête en session. Il ne faut pas hésiter à refaire une requête à la base de données pour chaque demande de l'utilisateur. Le cache de la base de données se charge d'améliorer les performances si les mêmes données sont demandées souvent.
Certains serveurs d'applications savent découper la session en tranches. Chaque clef de la session est récupérée sur disque à la demande. Avec cette stratégie, la session dans son ensemble n'est pas montée en mémoire lors du traitement d'un utilisateur. Seul les objets vraiment utilisés sont récupérés. Cette stratégie fonctionne si les développeurs utilisent des clefs avec des objets complets et riches, permettant le traitement du cas d'utilisation. Une clef par cas d'utilisation et les bénéfices sont là. Sinon, cela n'apporte rien, voire peut dégrader les performances.
De même, un nettoyage à l'intérieur de la session avec un algorithme de LRU (Last Rescent Used) permet de libérer de la mémoire des processus applicatifs n'étant plus nécessaires. C'est le moment de supprimer les objets des cas d'utilisations n'étant plus utilisés. Souvent, les développeurs ne nettoient pas la session à la fin d'un processus. Il est préférable de nettoyer les objets ayant permis un virement, si l'utilisateur est parti vérifier ses portefeuilles boursiers.
Si les sessions ont une taille raisonnable, la sauvegarde et la lecture sur disque prennent un temps négligeable. Il n'est alors pas nécessaire d'avoir beaucoup de sessions en mémoire. En effet, les sessions sont des objets à durée de vie longue. Il y a donc un effet lors de l'exécution du ramasse miettes générales (FullGC).
Si le dépôt des sessions sur disque entraîne une dégradation des performances, il est envisageable d'augmenter leur nombre en mémoire, en cohérence avec le nombre d'utilisateurs simultanés attendu. En cas de pic de charge, les sessions complémentaires seront gérées par le disque. Mais, il faut bien avoir conscience que cela à un impact sur le ramasse miettes et les performances.
La gestion des ressources J2EE
Pour résumer, tout est organisé dans les serveurs J2EE pour réduire au maximum la consommation mémoire. Le nombre de thread est limité ; le nombre de session en mémoire également ; tous les caches ont une taille limite. Une application en production doit respecter ces principes sous peine d'être incapable de tenir la charge et d'avoir une instabilités importantes.
  

Il faut éviter l'effet bouchon, lorsque les caches sont importants dans les premières étapes et trop petit dans les suivantes. Il est préférable d'accepter moins de requête mais de les satisfaire plus rapidement.
  

On peut résumer les stratégies d'optimisations des différents caches :
1. augmentez le nombre de threads et le pool de connexion en parallèle ;
2. augmentez le nombre de threads pour augmenter l'utilisation CPU ;
3. ajustez le cache des requêtes préparées par rapport au nombre de requêtes possibles ;
4. augmentez la taille de la pile TCP/IP pour garder les requêtes en attentes, par rapport au trafic attendu ;
5. Ajuster le nombre de sessions en mémoire suivant l'impact de la sauvegarde sur disque et le nombre d'utilisateurs simultanés du site.
La mémoire d'une application J2EE
Maintenant que nous avons vu comment fonctionne un serveur J2EE, regardons comment calculer la mémoire nécessaire à un applicatif. La première chose importante à savoir est qu'un applicatif J2EE doit pouvoir fonctionner avec tous les caches à zéro. C'est une évidence, mais peu de développeurs en ont conscience. Je viens de décrire toutes les techniques pour optimiser le code avec des caches, et je vous demande d'oublier tous cela ! Les caches sont là uniquement pour améliorer les performances, pas pour faire fonctionner l'application. Si l'application fonctionne avec les caches à zéro, elle fonctionnera avec des caches dont les limites auront été adaptées à ses exigences.
Il est beaucoup plus facile de calculer la taille minimum exigée par une application Java avec les caches à zéro. Il ne s'agit pas d'obtenir une application efficace, mais une application qui fonctionne et qui est capable de démontrer qu'elle ne possède pas de fuite mémoire.
Pour pouvoir faire les différents calculs, nous devons d'abord identifier le type d'application. En effet, nous pouvons séparer les applications en deux groupes : les applications sans états et les applications avec états. Les applications sans états sont des applications qui n'utilisent pas de sessions pour les utilisateurs. En dehors des caches, la mémoire est consommée le temps d'effectuer une requête HTTP, mais tout peut être nettoyé au terme du traitement. Pour reprendre l'explication du début de l'article, tous les objets ont une durée de vie courte, et peuvent être nettoyés (en théorie) sans exiger l'analyse complète de la mémoire. Dans les faits, comme l'algorithme de nettoyage rapide des objets à courte vie n'est pas capable d'identifier tous les objets orphelins, il reste quelques objets considérés à torts, comme des objets à grande durée de vie. Un développeur particulièrement Geek peut couper certains pointeurs en les forçant à null avant d'oublier les objets. Cela aide le ramasse miettes à qualifier les objets.
Sans état
Il n'est pas possible de calculer la taille mémoire d'un applicatif sans états. La seule démarche est d'utiliser une approche par essais/erreurs. Pour pouvoir faire cela, il faut d'abord un scénario utilisant le maximum de fonctionnalités de l'applicatif.
Ensuite, le premier objectif est d'obtenir la taille minimum permettant d'exécuter le scénario avec un seul utilisateur. Pour cela, il faut procéder par dichotomie en diminuant la taille maximum de la JVM. Il faut arriver à une situation ou le serveur d'applications arrive à démarrer, mais pas le scénario. En ajoutant un seul méga-octet, le scénario doit alors fonctionner. Cela correspond à la variable {max}. Parfois, il est nécessaire d'ajouter un peu plus et est signe d'un problème. Consommer plus d'un méga pour une requête sans état est étrange.
Nous déduisons de ce premier test, la taille du {serveur} et la taille complémentaire pour exécuter le scénario.
L'étape suivante consiste à déterminer le nombre de threads {nbt} pouvant être exécutés en parallèle sur le même scénario avec toujours la même taille mémoire {max}. On relance le serveur et on injecte plusieurs requêtes simultanément. On en déduit la taille réellement nécessaire à l'exécution du scénario. {taille scénario} = ({max} - {serveur}) / {nbt}
Suivant le nombre de threads à accepter en parallèle pour répondre aux besoins de charge, il est alors possible d'estimer la taille mémoire minimum pour pouvoir exécuter simultanément tous les traitements. {taille minimum}={serveur} + {nb thread} × {taille scénario}
Il n'est pas rare d'ajouter à ce résultat quinze pour-cent. Un test en charge doit confirmer le calcul. Des ajustements peuvent être nécessaires.
À cette étape, il ne s'agit pas d'optimisations. Le but est de faire fonctionner l'application, et de calculer la taille minimum avec tous les caches à zéro. La JVM doit indiquer très régulièrement le lancement du Full GC. Des paramètres permettent d'avoir cette information.
Dans cette situation, nous pouvons alors qualifier l'applicatif. En effet, il doit pouvoir fonctionner dans le temps, sans OutOfMemory. Si ce n'est pas le cas, il y a une fuite mémoire. Elle apparaîtra rapidement. Bien plus rapidement qu'avec beaucoup de mémoire. En effet, il n'est pas rare qu'un test fonctionne plusieurs heures alors qu'il existe une fuite mémoire.
J'ai été confronté à un programme qui avait besoin que de 17 Mo minimum, mais dont le projet avait exigé 1Go. Après 12 heures de traitements, des symptômes indiquaient une fuite mémoire, mais le programme fonctionnait toujours. Avec un test au limite minimum, un quart d'heure à suffit pour la déclencher.
L'erreur classique des projets est d'indiquer pour la taille minimum de la JVM, une taille maximum ! « Combien de mémoire vous avez ? Et bien c'est ce dont l'application à besoin » Finalement, lors du Full GC, l'application est interrompue pendant plusieurs dizaines de secondes.
Maintenant que nous connaissons la taille minimum, nous pouvons la doubler pour indiquer la taille maximum. Les caches peuvent alors être valorisés en conformité avec les besoins de l'applicatif.
Un test en charge peut être entrepris. Il faut chercher à saturer tous les caches. Le pool de connexion est saturé lorsque tous les threads sont utilisés. Le pool des requêtes-préparés est saturé si le scénario invoque chaque requête SQL.
Si des OutOfMemory apparaissent, c'est que les caches sont plus gourmands que prévu. Un ajustement progressif est alors nécessaire.
Il faut alors vérifier le temps pris par le Full GC lorsqu'il intervient. Le temps doit être raisonnable. Si c'est le cas, il ne sert à rien d'ajouter de la mémoire. Votre application est paramétré au mieux. Ajouter de la mémoire va dégrader les performances !
Pour consommer le reste de mémoire disponible, non utilisée par la JVM, le serveur peut éventuellement être mutualisé via différentes approches (installation de plusieurs applicatifs dans le même serveur d'applications, installation de plusieurs serveurs d'applications, installation de machine virtuelles, etc.) Cela est écologique car réduit la consommation électrique et la chaleur émise. Bien entendu, il faut regarder les impacts sur les performances de chaque applicatif.
Si le temps du Full GC est inacceptable, il faut réduire la taille mémoire maximum de la JVM et intervenir sur la taille des différents caches.
Avec état
Le calcul pour les applications avec état est légèrement différent. Il faut en effet, ajouter la taille de la session multipliée par le nombre de sessions gardées en mémoire. Si la taille des sessions est trop importante, il y aura inévitablement des crashs à terme. Les sessions ne doivent pas dépasser les 15Ko.
La taille minimum estimée devient alors : {taille minimum} = {serveur} + {nb thread} × {taille scénario} + {taille session} × {cache session}
Une marge de quinze à vingt pour-cent en plus est acceptable.
De même, un test en charge doit être effectué avec tous les caches à zéro. Il doit y avoir des Full GC en permanence, mais l'application ne doit pas planter. Sinon, il faut revoir la copie ;-) Les sessions doivent être trop gourmandes.
La taille maximum est de même, proche de {minimum} × 2, sauf si les paramètres des caches sont très importants. Un test en charge, après saturation des caches, doit confirmer que le temps du Full GC est bien inférieur à quelques secondes. Des ajustements peuvent être nécessaires pour approcher de cet objectif.
Si le temps du Full GC est inacceptable, il faut revoir l'application au niveau de la taille des sessions et réduire les différents caches.
En cas de problème avec la mémoire, il est possible d'obtenir un dump de celle-ci. Un kill -3 <pid> ou un jstack <pid> avec le JDK5 permet d'obtenir un fichier décrivant l'état de la mémoire. Cela aide à identifier les fuites. Seul le projet peut comprendre le résultat. L'intégration en est incapable, ne maîtrisant pas les tenants et les aboutissements du programme.
Les paramètres de JVM
Les paramètres principaux à indiquer pour une JVM, sont la taille minimum et la taille maximum (Tableau 1). Il existe des centaines de paramètres. Aucun n'est capable de corriger un programme. La taille réservée aux objets à durée de vie courte est automatiquement calculée par la JVM, voir adaptée dynamiquement avec le JRE 1.5. À la marge, quelques améliorations peuvent être obtenue, mais jamais autant qu'une amélioration des algorithmes ou de la consommation mémoire par le programme.
Paramètre
	Description
	-Xms<n>M
	Taille mémoire minimum
	-Xmx<n>M
	Taille mémoire maximum
	-verbose:gc
	Trace lors des algorithmes de ramasse miettes
	-Xloggc:<file>
	Fichier de log du ramasse miettes
	-XX:+PrintGCDetail
	Détail des log du ramasse miettes
	-XX:+PrintGCTimeStamps
	Durée des algorithmes du ramasse miettes
	Comme nous venons de le voir, il est contre productif d'indiquer une taille maximum sans cohérence avec les besoins réels de l'application.
Pour qualifier un applicatif avant sa mise en production, il doit démontrer qu'il ne possède pas de fuite mémoire, qu'il la consomme raisonnablement, en conformité avec les objectifs d'architecture des serveurs J2EE, et que le nettoyage de la mémoire ne fige pas le serveur d'applications au delà du raisonnable.
L'équipe de pré production doit prendre en charge ces différents tests, pour garantir une mise en production efficace. En ajustant les caches, les performances doivent s'améliorer, sans pour autant exiger trop de mémoire.
Ces approches théoriques sont parfois contredite par la réalité. Il faut tester et re-tester différentes combinaisons pour tenir les performances et la charge attendues.
Nous espérons vous avoir donné les clefs vous permettant d'ajuster au mieux vos applications avant la mise en production.